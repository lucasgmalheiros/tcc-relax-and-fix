{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_ml as fml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import hamming_loss, f1_score, jaccard_score, accuracy_score, multilabel_confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois posso separar uma análise para problemas que não haviam no teste (30 plantas, 5 produtos, etc) (o dataset mantém o índice no y_test, basta fazer merge das colunas para filtrar plantas, produtos e dps dar drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "TOLERANCE = 0.05\n",
    "with open(f'trained_models/oracle_{TOLERANCE}percent_balanced_calibrated.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set (\"new instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TOLERANCE_LIMIT = TOLERANCE / 100\n",
    "test_results = pd.read_csv('datasets/test_instances_results.csv')\n",
    "test_features = pd.read_csv('datasets/test_instances_features.csv')\n",
    "test_set = fml.create_dataset(test_features, test_results)\n",
    "test_set = fml.create_multi_label_target(test_set, TEST_TOLERANCE_LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_1_0 : 13\n",
      "RF_2_0 : 16\n",
      "RF_2_1 : 13\n",
      "RF_3_0 : 13\n",
      "RF_3_1 : 11\n",
      "RF_3_2 : 11\n",
      "RF_4_0 : 13\n",
      "RF_4_1 : 13\n",
      "RF_4_2 : 11\n",
      "RF_4_3 : 9\n",
      "RF_6_0 : 13\n",
      "RF_6_1 : 12\n",
      "RF_6_2 : 13\n",
      "RF_6_3 : 12\n",
      "RF_6_4 : 12\n",
      "RF_6_5 : 9\n",
      "RF_T_0 : 12\n"
     ]
    }
   ],
   "source": [
    "target_cols = [t for t in test_set.columns if t.startswith('RF')]\n",
    "for t in target_cols:\n",
    "    print(t, ':', test_set[t].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing (deve ser igual ao aplicado no desenvolvimento)\n",
    "X_test = test_set.drop(columns=target_cols + ['instance'])\n",
    "X_test = fml.binary_feature_selection(X_test)\n",
    "y_test = test_set[target_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(model.predict(X_test), columns=y_test.columns, index=y_test.index)\n",
    "probabilities = pd.DataFrame(model.predict_proba(X_test), columns=y_test.columns, index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.11764705882352941\n",
      "Micro-Averaged F1 Score: 0.8716577540106952\n",
      "Jaccard Similarity Score: 0.4619076797385621\n",
      "Subset Accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "hamming = hamming_loss(y_test, y_pred)\n",
    "print(\"Hamming Loss:\", hamming)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "print(\"Micro-Averaged F1 Score:\", f1)\n",
    "\n",
    "jaccard = jaccard_score(y_test, y_pred, average='samples')\n",
    "print(\"Jaccard Similarity Score:\", jaccard)\n",
    "\n",
    "subset_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Subset Accuracy:\", subset_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      RF_1_0       0.73      0.62      0.67        13\n",
      "      RF_2_0       1.00      0.75      0.86        16\n",
      "      RF_2_1       1.00      0.77      0.87        13\n",
      "      RF_3_0       1.00      0.77      0.87        13\n",
      "      RF_3_1       1.00      0.91      0.95        11\n",
      "      RF_3_2       1.00      0.73      0.84        11\n",
      "      RF_4_0       1.00      0.77      0.87        13\n",
      "      RF_4_1       1.00      0.77      0.87        13\n",
      "      RF_4_2       1.00      0.82      0.90        11\n",
      "      RF_4_3       0.88      0.78      0.82         9\n",
      "      RF_6_0       1.00      0.77      0.87        13\n",
      "      RF_6_1       1.00      0.83      0.91        12\n",
      "      RF_6_2       1.00      0.77      0.87        13\n",
      "      RF_6_3       1.00      0.83      0.91        12\n",
      "      RF_6_4       1.00      0.83      0.91        12\n",
      "      RF_6_5       0.89      0.89      0.89         9\n",
      "      RF_T_0       1.00      0.92      0.96        12\n",
      "\n",
      "   micro avg       0.97      0.79      0.87       206\n",
      "   macro avg       0.97      0.80      0.87       206\n",
      "weighted avg       0.97      0.79      0.87       206\n",
      " samples avg       0.57      0.47      0.49       206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucasmalheiros/Documents/Pesquisa Operacional/tcc-relax-and-fix/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=y_test.columns, zero_division=\"warn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_evaluation_results = []\n",
    "for method in y_test.columns:\n",
    "    # Calculate true positives (correct assignments)\n",
    "    true_positives = ((y_pred == 1) & (y_test == 1))[method].sum()\n",
    "\n",
    "    # Calculate false positives (predicted as 1 but actual is 0)\n",
    "    false_positives = ((y_pred == 1) & (y_test == 0))[method].sum()\n",
    "\n",
    "    # Calculate false negatives (predicted as 0 but actual is 1)\n",
    "    false_negatives = ((y_pred == 0) & (y_test == 1))[method].sum()\n",
    "\n",
    "    # Calculate Precision\n",
    "    if (true_positives + false_positives) > 0:\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "    else:\n",
    "        precision = 0\n",
    "\n",
    "    # Calculate Recall\n",
    "    if (true_positives + false_negatives) > 0:\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "    else:\n",
    "        recall = 0 \n",
    "\n",
    "    # Calculate F1-Score\n",
    "    if (precision + recall) > 0:\n",
    "        f1_score = (2 * precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1_score = 0\n",
    "\n",
    "    # Append results to the list\n",
    "    method_evaluation_results.append({\n",
    "        'Method': method,\n",
    "        'True Positives': true_positives,\n",
    "        'False Positives': false_positives,\n",
    "        'False Negatives': false_negatives,\n",
    "        'Precision (%)': f'{precision * 100 :.2f}',\n",
    "        'Recall (%)': f'{recall * 100 :.2f}',\n",
    "        'F1-Score': f'{f1_score * 100 :.2f}'\n",
    "    })\n",
    "method_evaluation_results_df = pd.DataFrame(method_evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Precision (%)</th>\n",
       "      <th>Recall (%)</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_1_0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>72.73</td>\n",
       "      <td>61.54</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF_2_0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>100.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF_2_1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>76.92</td>\n",
       "      <td>86.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF_3_0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>76.92</td>\n",
       "      <td>86.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_3_1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00</td>\n",
       "      <td>90.91</td>\n",
       "      <td>95.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF_3_2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>72.73</td>\n",
       "      <td>84.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF_4_0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>76.92</td>\n",
       "      <td>86.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF_4_1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>76.92</td>\n",
       "      <td>86.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF_4_2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>81.82</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF_4_3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>87.50</td>\n",
       "      <td>77.78</td>\n",
       "      <td>82.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF_6_0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>76.92</td>\n",
       "      <td>86.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF_6_1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>83.33</td>\n",
       "      <td>90.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RF_6_2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00</td>\n",
       "      <td>76.92</td>\n",
       "      <td>86.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RF_6_3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>83.33</td>\n",
       "      <td>90.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF_6_4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>83.33</td>\n",
       "      <td>90.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RF_6_5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88.89</td>\n",
       "      <td>88.89</td>\n",
       "      <td>88.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RF_T_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00</td>\n",
       "      <td>91.67</td>\n",
       "      <td>95.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Method  True Positives  False Positives  False Negatives Precision (%)  \\\n",
       "0   RF_1_0               8                3                5         72.73   \n",
       "1   RF_2_0              12                0                4        100.00   \n",
       "2   RF_2_1              10                0                3        100.00   \n",
       "3   RF_3_0              10                0                3        100.00   \n",
       "4   RF_3_1              10                0                1        100.00   \n",
       "5   RF_3_2               8                0                3        100.00   \n",
       "6   RF_4_0              10                0                3        100.00   \n",
       "7   RF_4_1              10                0                3        100.00   \n",
       "8   RF_4_2               9                0                2        100.00   \n",
       "9   RF_4_3               7                1                2         87.50   \n",
       "10  RF_6_0              10                0                3        100.00   \n",
       "11  RF_6_1              10                0                2        100.00   \n",
       "12  RF_6_2              10                0                3        100.00   \n",
       "13  RF_6_3              10                0                2        100.00   \n",
       "14  RF_6_4              10                0                2        100.00   \n",
       "15  RF_6_5               8                1                1         88.89   \n",
       "16  RF_T_0              11                0                1        100.00   \n",
       "\n",
       "   Recall (%) F1-Score  \n",
       "0       61.54    66.67  \n",
       "1       75.00    85.71  \n",
       "2       76.92    86.96  \n",
       "3       76.92    86.96  \n",
       "4       90.91    95.24  \n",
       "5       72.73    84.21  \n",
       "6       76.92    86.96  \n",
       "7       76.92    86.96  \n",
       "8       81.82    90.00  \n",
       "9       77.78    82.35  \n",
       "10      76.92    86.96  \n",
       "11      83.33    90.91  \n",
       "12      76.92    86.96  \n",
       "13      83.33    90.91  \n",
       "14      83.33    90.91  \n",
       "15      88.89    88.89  \n",
       "16      91.67    95.65  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_evaluation_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select top K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF_1_0</th>\n",
       "      <th>RF_2_0</th>\n",
       "      <th>RF_2_1</th>\n",
       "      <th>RF_3_0</th>\n",
       "      <th>RF_3_1</th>\n",
       "      <th>RF_3_2</th>\n",
       "      <th>RF_4_0</th>\n",
       "      <th>RF_4_1</th>\n",
       "      <th>RF_4_2</th>\n",
       "      <th>RF_4_3</th>\n",
       "      <th>RF_6_0</th>\n",
       "      <th>RF_6_1</th>\n",
       "      <th>RF_6_2</th>\n",
       "      <th>RF_6_3</th>\n",
       "      <th>RF_6_4</th>\n",
       "      <th>RF_6_5</th>\n",
       "      <th>RF_T_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RF_1_0  RF_2_0  RF_2_1  RF_3_0  RF_3_1  RF_3_2  RF_4_0  RF_4_1  RF_4_2  \\\n",
       "2        0       0       0       0       0       1       0       0       0   \n",
       "0        0       0       0       0       0       0       0       0       0   \n",
       "4        1       1       1       0       0       0       0       0       0   \n",
       "13       0       0       0       0       0       1       0       0       1   \n",
       "23       0       0       0       0       0       1       0       0       0   \n",
       "\n",
       "    RF_4_3  RF_6_0  RF_6_1  RF_6_2  RF_6_3  RF_6_4  RF_6_5  RF_T_0  \n",
       "2        0       0       0       1       1       0       0       0  \n",
       "0        0       1       0       0       1       0       0       1  \n",
       "4        0       0       0       0       0       0       0       0  \n",
       "13       0       0       0       0       1       0       0       0  \n",
       "23       0       0       0       1       1       0       0       0  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_methods = np.argsort(-probabilities, axis=1)\n",
    "# Top-K Selection: Select top-K methods based on ranking\n",
    "TOP_K = 3\n",
    "top_k_methods = np.zeros_like(probabilities, dtype=int)\n",
    "\n",
    "# Set top-K methods as selected (binary)\n",
    "for i, row in enumerate(ranked_methods):\n",
    "    top_indices = row[:TOP_K]  # Get top-K indices for this instance\n",
    "    top_k_methods[i, top_indices] = 1\n",
    "\n",
    "# Convert to DataFrame for comparison\n",
    "top_k_methods_df = pd.DataFrame(top_k_methods, columns=y_test.columns, index=y_test.index)\n",
    "\n",
    "# Display the top-K selected methods\n",
    "top_k_methods_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct Predictions: 46.0\n",
      "\n",
      "Correct Predictions Per Instance:\n",
      "2     3.0\n",
      "0     3.0\n",
      "4     1.0\n",
      "13    3.0\n",
      "23    3.0\n",
      "21    1.0\n",
      "7     3.0\n",
      "16    3.0\n",
      "18    3.0\n",
      "17    3.0\n",
      "14    0.0\n",
      "12    3.0\n",
      "10    3.0\n",
      "8     0.0\n",
      "3     1.0\n",
      "15    1.0\n",
      "20    0.0\n",
      "19    1.0\n",
      "22    0.0\n",
      "5     2.0\n",
      "1     2.0\n",
      "6     3.0\n",
      "11    1.0\n",
      "9     3.0\n",
      "dtype: float64\n",
      "\n",
      "Accuracy: 63.89%\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication to find correct predictions\n",
    "correct_predictions = top_k_methods_df * test_set\n",
    "\n",
    "# Sum the total number of correct predictions\n",
    "total_correct = correct_predictions.sum().sum()  # Sum across all rows and columns\n",
    "print(f\"Total Correct Predictions: {total_correct}\")\n",
    "\n",
    "# Optionally, calculate the number of correct predictions per instance\n",
    "correct_per_instance = correct_predictions.sum(axis=1)\n",
    "print(\"\\nCorrect Predictions Per Instance:\")\n",
    "print(correct_per_instance)\n",
    "\n",
    "# Optionally, calculate the accuracy as a percentage\n",
    "total_possible = TOP_K * len(top_k_methods_df)  # Total number of actual positive labels\n",
    "accuracy = (total_correct / total_possible) * 100\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Precision\n",
    "if TOP_K == 1:\n",
    "    precision = total_correct / len(y_test) * 100\n",
    "    print(f\"Precision: {precision:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows with All Incorrect Predictions: 4\n",
      "Percentage of Rows with All Incorrect Predictions: 16.67%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Calculate the number of correct predictions per row (instance)\n",
    "correct_per_instance = correct_predictions.sum(axis=1)\n",
    "\n",
    "# Step 2: Identify rows with zero correct predictions\n",
    "missed_all = (correct_per_instance == 0).sum()  # Count rows with no correct predictions\n",
    "total_instances = len(correct_predictions)  # Total number of rows\n",
    "\n",
    "# Step 3: Calculate the accuracy for missed rows\n",
    "missed_accuracy = (missed_all / total_instances) * 100\n",
    "\n",
    "# Output the results\n",
    "print(f\"Number of Rows with All Incorrect Predictions: {missed_all}\")\n",
    "print(f\"Percentage of Rows with All Incorrect Predictions: {missed_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance what if only 1 method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize a DataFrame to store results\n",
    "method_evaluation_results = []\n",
    "\n",
    "# Step 2: Loop through each method\n",
    "for method in y_test.columns:\n",
    "    # Create a binary matrix where the current method is always 1 and others are 0\n",
    "    single_method_matrix = np.zeros_like(y_test, dtype=int)\n",
    "    single_method_matrix[:, y_test.columns.get_loc(method)] = 1  # Set current method column to 1\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    single_method_df = pd.DataFrame(single_method_matrix, columns=y_test.columns, index=y_test.index)\n",
    "\n",
    "    # Calculate true positives (correct assignments)\n",
    "    true_positives = ((single_method_df == 1) & (y_test == 1))[method].sum()\n",
    "\n",
    "    # Calculate false positives (predicted as 1 but actual is 0)\n",
    "    false_positives = ((single_method_df == 1) & (y_test == 0))[method].sum()\n",
    "\n",
    "    # Calculate false negatives (predicted as 0 but actual is 1)\n",
    "    false_negatives = ((single_method_df == 0) & (y_test == 1))[method].sum()\n",
    "\n",
    "    # Calculate Precision\n",
    "    if (true_positives + false_positives) > 0:\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "    else:\n",
    "        precision = 0.0  # Handle division by zero\n",
    "\n",
    "    # Calculate Recall\n",
    "    if (true_positives + false_negatives) > 0:\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "    else:\n",
    "        recall = 0.0  # Handle division by zero\n",
    "\n",
    "    # Append results to the list\n",
    "    method_evaluation_results.append({\n",
    "        'Method': method,\n",
    "        'True Positives': true_positives,\n",
    "        'False Positives': false_positives,\n",
    "        'False Negatives': false_negatives,\n",
    "        'Precision (%)': precision * 100,\n",
    "        'Recall (%)': recall * 100\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negatives</th>\n",
       "      <th>Precision (%)</th>\n",
       "      <th>Recall (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_1_0</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>54.166667</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF_2_0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF_2_1</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>54.166667</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF_3_0</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>54.166667</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_3_1</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF_3_2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF_4_0</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>54.166667</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF_4_1</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>54.166667</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF_4_2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF_4_3</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF_6_0</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>54.166667</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF_6_1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RF_6_2</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>54.166667</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RF_6_3</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF_6_4</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RF_6_5</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RF_T_0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Method  True Positives  False Positives  False Negatives  Precision (%)  \\\n",
       "0   RF_1_0              13               11                0      54.166667   \n",
       "1   RF_2_0              16                8                0      66.666667   \n",
       "2   RF_2_1              13               11                0      54.166667   \n",
       "3   RF_3_0              13               11                0      54.166667   \n",
       "4   RF_3_1              11               13                0      45.833333   \n",
       "5   RF_3_2              11               13                0      45.833333   \n",
       "6   RF_4_0              13               11                0      54.166667   \n",
       "7   RF_4_1              13               11                0      54.166667   \n",
       "8   RF_4_2              11               13                0      45.833333   \n",
       "9   RF_4_3               9               15                0      37.500000   \n",
       "10  RF_6_0              13               11                0      54.166667   \n",
       "11  RF_6_1              12               12                0      50.000000   \n",
       "12  RF_6_2              13               11                0      54.166667   \n",
       "13  RF_6_3              12               12                0      50.000000   \n",
       "14  RF_6_4              12               12                0      50.000000   \n",
       "15  RF_6_5               9               15                0      37.500000   \n",
       "16  RF_T_0              12               12                0      50.000000   \n",
       "\n",
       "    Recall (%)  \n",
       "0        100.0  \n",
       "1        100.0  \n",
       "2        100.0  \n",
       "3        100.0  \n",
       "4        100.0  \n",
       "5        100.0  \n",
       "6        100.0  \n",
       "7        100.0  \n",
       "8        100.0  \n",
       "9        100.0  \n",
       "10       100.0  \n",
       "11       100.0  \n",
       "12       100.0  \n",
       "13       100.0  \n",
       "14       100.0  \n",
       "15       100.0  \n",
       "16       100.0  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Convert results to a DataFrame for easier visualization\n",
    "method_evaluation_results_df = pd.DataFrame(method_evaluation_results)\n",
    "\n",
    "# Display the evaluation results\n",
    "method_evaluation_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
